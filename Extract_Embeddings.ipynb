{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88b63362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "from glob import glob\n",
    "from collections import Counter, defaultdict\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import BertModel,BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebf960ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = os.path.join('data','preprocessed')\n",
    "sample_file = os.path.join('data','preprocessed','sample_target_index.dict')\n",
    "outdir = os.path.join('data','preprocessed')\n",
    "out_file = os.path.join('data','preprocessed','cofea_sampled_vectors')\n",
    "batch_size = 200\n",
    "layers = '10,11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13ab3c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect index of tokens in the documents\n",
    "files = sorted(glob(os.path.join(in_dir, '*_tokenized.jsonlist')))\n",
    "docs = []\n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        docs.append(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cc56b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample index\n",
    "with open(sample_file,'rb') as f:\n",
    "    sample_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217c003d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#layers\n",
    "layers = [int(layer) for layer in layers.split(',')]\n",
    "\n",
    "# load the model\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# move the model to the GPU\n",
    "device = 'cuda'\n",
    "if torch.cuda.is_available():\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adc00f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(token_ids, target_position, sequence_length=128):\n",
    "    \"\"\"\n",
    "    Given a text containing a target word, return the sentence snippet which surrounds the target word\n",
    "    (and the target word's position in the snippet).\n",
    "    :param token_ids: list of token ids (for an entire line of text)\n",
    "    :param target_position: index of the target word's position in `tokens`\n",
    "    :param sequence_length: desired length for output sequence (e.g. 128, 256, 512)\n",
    "    :return: (context_ids, new_target_position)\n",
    "                context_ids: list of token ids for the output sequence\n",
    "                new_target_position: index of the target word's position in `context_ids`\n",
    "    \"\"\"\n",
    "    # -2 as [CLS] and [SEP] tokens will be added later; /2 as it's a one-sided window\n",
    "    window_size = int((sequence_length - 2) / 2)\n",
    "    context_start = max([0, target_position - window_size])\n",
    "    padding_offset = max([0, window_size - target_position])\n",
    "    padding_offset += max([0, target_position + window_size - len(token_ids)])\n",
    "\n",
    "    context_ids = token_ids[context_start:target_position + window_size]\n",
    "    context_ids += padding_offset * [0]\n",
    "\n",
    "    new_target_position = target_position - context_start\n",
    "\n",
    "    return context_ids, new_target_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3b29c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–Š                                                        | 14/1064 [11:43<23:00:05, 78.86s/it]"
     ]
    }
   ],
   "source": [
    "# Just put the output into some lists for now\n",
    "token_index_list = []\n",
    "to_encode = []\n",
    "vectors_by_layer = defaultdict(dict)\n",
    "for layer in layers:\n",
    "    vectors_by_layer[layer] = defaultdict(list)\n",
    "    \n",
    "for target_word in tqdm(sample_index):\n",
    "    for line_index,example_info in enumerate(sample_index[target_word]):\n",
    "        file_id,doc_id,index = example_info\n",
    "        doc = json.loads(docs[file_id][doc_id])\n",
    "        tokens = doc['tokens']\n",
    "        # now we get the context\n",
    "        context_ids, pos_in_context = get_context(tokens, index)\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(\n",
    "            ['[CLS]']+context_ids+['[SEP]'])\n",
    "        to_encode.append(input_ids)\n",
    "        token_index_list.append(pos_in_context+1) #increment because we add CLS\n",
    "        # we reached the batch limit and wil, now extract BERT embeddings\n",
    "        if len(to_encode) == batch_size or (line_index == (len(sample_index[target_word])-1) and len(to_encode)>1):\n",
    "            input_tensors = torch.tensor(to_encode)\n",
    "            input_tensors = input_tensors.to(device)\n",
    "            n_rows, n_tokens = input_tensors.shape\n",
    "            with torch.no_grad():\n",
    "                try:\n",
    "                    # run usages through language model\n",
    "                    outputs = model(input_tensors,output_hidden_states=True)\n",
    "                    hidden_states = outputs[2]\n",
    "                    vectors_np = {layer: hidden_states[layer].detach().cpu().numpy() for layer in layers}\n",
    "                    # save the first token of the target word in each example\n",
    "                    for row in np.arange(len(token_index_list)):\n",
    "                        pos = token_index_list[row]\n",
    "                        for layer in layers:\n",
    "                            vectors_by_layer[layer][target_word].append(\n",
    "                                np.array(vectors_np[layer][row, pos, :].copy(), dtype=np.float32))                        \n",
    "                        \n",
    "                except Exception as e:\n",
    "                        print(len(to_encode))\n",
    "                        raise e\n",
    "            \n",
    "            \n",
    "            to_encode = []\n",
    "            token_index_list = []\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50fd0f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in layers:\n",
    "    with open(out_file+'_layer_'+str(layer)+'.dict','wb') as f:\n",
    "        pickle.dump(vectors_by_layer[layer],file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
